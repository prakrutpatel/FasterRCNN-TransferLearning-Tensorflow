{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faster RCNN Training on Serengeti.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FIqnjbWYsuQw",
        "2FKFq8RXs6bs",
        "MFyCeiBb9BbS"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakrutpatel/FasterRCNN-TransferLearning-Tensorflow/blob/main/Faster_RCNN_Training_on_Serengeti.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW2W17o-p7SX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5c8308-a2e2-41e9-f35e-d480f2ba7c0a"
      },
      "source": [
        "!pip install tensorflow_gpu==1.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_gpu==1.15\n",
            "  Downloading tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (411.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5 MB 5.8 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (1.46.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (3.3.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (0.2.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 63.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (1.14.1)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 43.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (1.21.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow_gpu==1.15) (3.17.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow_gpu==1.15) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (3.3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow_gpu==1.15) (3.8.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow_gpu==1.15) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=ed15fa17ad21d7a61eecdece7953a443c11a7342a2d22a7e5ed28910bc5a6573\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires tensorboard<2.9,>=2.8, but you have tensorboard 1.15.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 1.15.1 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.19.5\n",
        "!pip uninstall -y pycocotools\n",
        "!pip install pycocotools --no-binary pycocotools"
      ],
      "metadata": {
        "id": "0y62xfiOCSJg",
        "outputId": "d7f56c7d-fd7d-42b7-8616-2249c1c3f976",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Found existing installation: pycocotools 2.0.4\n",
            "Uninstalling pycocotools-2.0.4:\n",
            "  Successfully uninstalled pycocotools-2.0.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycocotools\n",
            "  Using cached pycocotools-2.0.4.tar.gz (106 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pycocotools) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp37-cp37m-linux_x86_64.whl size=265197 sha256=fe09ca4e1e745500f32c063565960779f0c13e5a040f7eb4f34999e0fee0321d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/5f/fa/f011e578cc76e1fc5be8dce30b3eb9fd00f337e744b3bba59b\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "Successfully installed pycocotools-2.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "5Xh3JAzyQEoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4V-XE6kbkc1"
      },
      "source": [
        "## Clone the `tensorflow-object-detection` repository or your fork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxc3DmvLQF3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e55e50e-8fd2-464c-8c6e-bbe77f2482cd"
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'tensorflow-object-detection-faster-rcnn'...\n",
            "remote: Enumerating objects: 885, done.\u001b[K\n",
            "remote: Total 885 (delta 0), reused 0 (delta 0), pack-reused 885\u001b[K\n",
            "Receiving objects: 100% (885/885), 24.83 MiB | 38.35 MiB/s, done.\n",
            "Resolving deltas: 100% (428/428), done.\n",
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d1731e4-626f-4dbf-b48b-7254c0256573"
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib pycocotools tf_slim\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 155639 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.6_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.6) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.7_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.7) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.6) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.7) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "\u001b[K     |████████████████████████████████| 352 kB 5.1 MB/s \n",
            "\u001b[?25h/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydc5HamQ4hSd",
        "outputId": "980275a1-3da9-4c04-e82b-ea17b86fd37a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-k7uGThXlny"
      },
      "source": [
        "## Prepare `tfrecord` files\n",
        "\n",
        "Roboflow automatically creates our TFRecord and label_map files that we need!\n",
        "\n",
        "**Generating your own TFRecords the only step you need to change for your own custom dataset.**\n",
        "\n",
        "Because we need one TFRecord file for our training data, and one TFRecord file for our test data, we'll create two separate datasets in Roboflow and generate one set of TFRecords for each.\n",
        "\n",
        "To create a dataset in Roboflow and generate TFRecords, follow [this step-by-step guide](https://blog.roboflow.ai/getting-started-with-roboflow/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNfIPc5yxDOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d79441e5-99dc-4690-80c1-ce7322f343cb"
      },
      "source": [
        "%cd /content/tensorflow-object-detection-faster-rcnn/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb_FMcfnSbRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a3408c-59dc-467b-c1d9-c0fae95048ad"
      },
      "source": [
        "!curl -L \"https://app.roboflow.com/ds/4DemUlSMP4?key=OPFgu1ApfM\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   896  100   896    0     0   1886      0 --:--:-- --:--:-- --:--:--  1886\n",
            "100 40.3M  100 40.3M    0     0  39.9M      0  0:00:01  0:00:01 --:--:--  267M\n",
            "Archive:  roboflow.zip\n",
            " extracting: README.dataset.txt      \n",
            " extracting: README.roboflow.txt     \n",
            "   creating: test/\n",
            " extracting: test/tortoise.tfrecord  \n",
            " extracting: test/tortoise_label_map.pbtxt  \n",
            "   creating: train/\n",
            " extracting: train/tortoise.tfrecord  \n",
            " extracting: train/tortoise_label_map.pbtxt  \n",
            "   creating: valid/\n",
            " extracting: valid/tortoise.tfrecord  \n",
            " extracting: valid/tortoise_label_map.pbtxt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T58u1YP9sUW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a35d37d-4a30-480f-fc4a-137d583cea7b"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FYI.txt  README.dataset.txt  README.roboflow.txt  \u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  \u001b[01;34mvalid\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5qhOGaTTFsq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f5cf19b-f014-4063-adc5-ea1d9a69d18b"
      },
      "source": [
        "# check out what we have in train\n",
        "%ls train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tortoise_label_map.pbtxt  tortoise.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKnnSSBu_XXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8dc5867-51ff-4d34-86cd-fe910285a455"
      },
      "source": [
        "# show what we have in test\n",
        "%ls test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tortoise_label_map.pbtxt  tortoise.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV"
      },
      "source": [
        "# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n",
        "test_record_fname = '/content/drive/MyDrive/B004_context_rcnn_memory_test'\n",
        "train_record_fname = '/content/drive/MyDrive/B004_context_rcnn_memory_train'\n",
        "label_map_pbtxt_fname = '/content/tortoise_label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8"
      },
      "source": [
        "## Download base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9410fb3-47df-47fd-c07f-807497b562a8"
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "fr = 'http://storage.googleapis.com/download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_coco_11_06_2017.tar.gz'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    #urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "    urllib.request.urlretrieve(fr,'faster_rcnn_resnet101_coco_11_06_2017.tar.gz')\n",
        "\n",
        "\n",
        "tar = tarfile.open('faster_rcnn_resnet101_coco_11_06_2017.tar.gz')#MODEL_FILE\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!wget \"http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_snapshot_serengeti_2020_06_10.tar.gz\"\n",
        "!tar -xvf \"faster_rcnn_resnet101_snapshot_serengeti_2020_06_10.tar.gz\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSBg1blhXzRX",
        "outputId": "e77341fa-3a32-491f-c36b-54320ba1b320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2022-06-25 17:08:44--  http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_snapshot_serengeti_2020_06_10.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.204.128, 2607:f8b0:400c:c15::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.204.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 588829839 (562M) [application/x-tar]\n",
            "Saving to: ‘faster_rcnn_resnet101_snapshot_serengeti_2020_06_10.tar.gz’\n",
            "\n",
            "faster_rcnn_resnet1 100%[===================>] 561.55M   178MB/s    in 3.1s    \n",
            "\n",
            "2022-06-25 17:08:47 (178 MB/s) - ‘faster_rcnn_resnet101_snapshot_serengeti_2020_06_10.tar.gz’ saved [588829839/588829839]\n",
            "\n",
            "faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/\n",
            "faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/model.ckpt.data-00000-of-00001\n",
            "faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/checkpoint\n",
            "faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/pipeline.config\n",
            "faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/model.ckpt.index\n",
            "faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/frozen_inference_graph.pb\n",
            "faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/model.ckpt.meta\n",
            "faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/saved_model/\n",
            "faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/saved_model/saved_model.pb\n",
            "faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/saved_model/variables/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_fname = \"/content/faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/pipeline.config\""
      ],
      "metadata": {
        "id": "dnR5SyR_ZQeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhvAObeiIix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5204870-b32d-41a5-b007-ba5a116ae70d"
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{DEST_DIR}\n",
            "ls: cannot access '{DEST_DIR}': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fc9adb81-8838-4562-e2bc-b62d7aa05054"
      },
      "source": [
        "fine_tune_checkpoint = \"/content/faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/model.ckpt\"\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/model.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU"
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8iFP5NyZqHF",
        "outputId": "d68aa0d7-5003-4c96-8d1e-b02ca804ee08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU"
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI"
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc691f6f-40a3-4ea5-e431-aa78e52fd0c3"
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model {\n",
            "  faster_rcnn {\n",
            "    num_classes: 1\n",
            "    image_resizer {\n",
            "      keep_aspect_ratio_resizer {\n",
            "        min_dimension: 600\n",
            "        max_dimension: 1024\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: \"faster_rcnn_resnet101\"\n",
            "      first_stage_features_stride: 16\n",
            "    }\n",
            "    first_stage_anchor_generator {\n",
            "      grid_anchor_generator {\n",
            "        height_stride: 16\n",
            "        width_stride: 16\n",
            "        scales: 0.25\n",
            "        scales: 0.5\n",
            "        scales: 1.0\n",
            "        scales: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "      }\n",
            "    }\n",
            "    first_stage_box_predictor_conv_hyperparams {\n",
            "      op: CONV\n",
            "      regularizer {\n",
            "        l2_regularizer {\n",
            "          weight: 0.0\n",
            "        }\n",
            "      }\n",
            "      initializer {\n",
            "        truncated_normal_initializer {\n",
            "          stddev: 0.009999999776482582\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    first_stage_nms_score_threshold: 0.0\n",
            "    first_stage_nms_iou_threshold: 0.699999988079071\n",
            "    first_stage_max_proposals: 300\n",
            "    first_stage_localization_loss_weight: 2.0\n",
            "    first_stage_objectness_loss_weight: 1.0\n",
            "    initial_crop_size: 14\n",
            "    maxpool_kernel_size: 2\n",
            "    maxpool_stride: 2\n",
            "    second_stage_box_predictor {\n",
            "      mask_rcnn_box_predictor {\n",
            "        fc_hyperparams {\n",
            "          op: FC\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.0\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            variance_scaling_initializer {\n",
            "              factor: 1.0\n",
            "              uniform: true\n",
            "              mode: FAN_AVG\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 1.0\n",
            "      }\n",
            "    }\n",
            "    second_stage_post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 0.0\n",
            "        iou_threshold: 0.6000000238418579\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 300\n",
            "      }\n",
            "      score_converter: SOFTMAX\n",
            "    }\n",
            "    second_stage_localization_loss_weight: 2.0\n",
            "    second_stage_classification_loss_weight: 1.0\n",
            "    output_final_box_features: true\n",
            "  }\n",
            "}\n",
            "train_config {\n",
            "  batch_size: 4\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  optimizer {\n",
            "    momentum_optimizer {\n",
            "      learning_rate {\n",
            "        manual_step_learning_rate {\n",
            "          initial_learning_rate: 0.01\n",
            "          schedule {\n",
            "            step: 1500\n",
            "            learning_rate: 0.005\n",
            "          }\n",
            "          schedule {\n",
            "            step: 2500\n",
            "            learning_rate: 0.0001\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.8999999761581421\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  gradient_clipping_by_norm: 10.0\n",
            "  fine_tune_checkpoint: \"/content/faster_rcnn_resnet101_snapshot_serengeti_2020_06_10/model.ckpt\"\n",
            "  from_detection_checkpoint: true\n",
            "  load_all_detection_checkpoint_vars: true\n",
            "  fine_tune_checkpoint_type: \"detection\"\n",
            "  use_bfloat16: false\n",
            "}\n",
            "train_input_reader {\n",
            "  label_map_path: \"/content/tortoise_label_map.pbtxt\"\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/drive/MyDrive/B004_context_rcnn_memory_train\"\n",
            "  }\n",
            "}\n",
            "eval_config {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  use_moving_averages: false\n",
            "}\n",
            "eval_input_reader {\n",
            "  label_map_path: \"/content/tortoise_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_epochs: 1\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/drive/MyDrive/B004_context_rcnn_memory_test\"\n",
            "  }\n",
            "  sample_1_of_n_examples: 1000\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB"
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nC7_syR1SJ9F",
        "outputId": "cef3a1ca-aeea-4a4f-9011-7425e5faacb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install lvis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.11.0)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.30)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.0.9)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.1.0->lvis) (4.1.1)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a70490-8dd9-429b-f98b-b2740d29a927"
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0623 23:33:51.874074 139948988630912 model_lib.py:839] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
            "I0623 23:33:51.874286 139948988630912 config_util.py:552] Maybe overwriting train_steps: 5000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0623 23:33:51.874388 139948988630912 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0623 23:33:51.874489 139948988630912 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0623 23:33:51.874585 139948988630912 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0623 23:33:51.874698 139948988630912 model_lib.py:855] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0623 23:33:51.874796 139948988630912 model_lib.py:892] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f47e6247d90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0623 23:33:51.875242 139948988630912 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f47e6247d90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f47e6186b00>) includes params argument, but params are not passed to Estimator.\n",
            "W0623 23:33:51.875467 139948988630912 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f47e6186b00>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0623 23:33:51.875859 139948988630912 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0623 23:33:51.876043 139948988630912 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0623 23:33:51.876269 139948988630912 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0623 23:33:51.880846 139948988630912 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_train']\n",
            "I0623 23:33:51.902736 139948988630912 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_train']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_train']\n",
            "I0623 23:33:51.905507 139948988630912 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_train']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0623 23:33:51.905637 139948988630912 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0623 23:33:51.905723 139948988630912 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0623 23:33:51.910925 139948988630912 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0623 23:33:51.927555 139948988630912 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:113: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0623 23:34:03.331697 139948988630912 deprecation.py:323] From /content/models/research/object_detection/inputs.py:113: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0623 23:34:03.478208 139948988630912 deprecation.py:323] From /content/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:288: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0623 23:34:08.326807 139948988630912 deprecation.py:323] From /content/models/research/object_detection/inputs.py:288: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0623 23:34:13.369565 139948988630912 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:34:13.485755 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0623 23:34:13.488323 139948988630912 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:34:16.399711 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:34:16.515791 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0623 23:34:16.516149 139948988630912 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:479: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0623 23:34:18.600287 139948988630912 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:479: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:34:18.614948 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0623 23:34:18.856704 139948988630912 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:34:18.858603 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:34:18.872875 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:461: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0623 23:34:19.675296 139948988630912 deprecation.py:323] From /content/models/research/object_detection/core/losses.py:461: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0623 23:34:25.626601 139948988630912 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0623 23:34:25.628191 139948988630912 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0623 23:34:28.925617 139948988630912 monitored_session.py:240] Graph was finalized.\n",
            "2022-06-23 23:34:28.925985: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-06-23 23:34:28.930235: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-06-23 23:34:28.930412: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14f7b800 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-06-23 23:34:28.930464: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-06-23 23:34:28.932265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-06-23 23:34:29.198401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:34:29.199097: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14f78380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-06-23 23:34:29.199125: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2022-06-23 23:34:29.200261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:34:29.200811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-06-23 23:34:29.211982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-23 23:34:29.359413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-23 23:34:29.427078: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-06-23 23:34:29.462560: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-06-23 23:34:29.636579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-06-23 23:34:29.741979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-06-23 23:34:30.084558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-06-23 23:34:30.084755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:34:30.085393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:34:30.085945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-06-23 23:34:30.086044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-23 23:34:30.087498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-06-23 23:34:30.087529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-06-23 23:34:30.087541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-06-23 23:34:30.087701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:34:30.088256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:34:30.088800: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-06-23 23:34:30.088851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0623 23:34:33.630777 139948988630912 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0623 23:34:33.899972 139948988630912 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0623 23:34:41.502327 139948988630912 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2022-06-23 23:34:49.720257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-23 23:34:55.248114: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:loss = 0.5520858, step = 0\n",
            "I0623 23:35:05.434193 139948988630912 basic_session_run_hooks.py:262] loss = 0.5520858, step = 0\n",
            "INFO:tensorflow:global_step/sec: 1.26268\n",
            "I0623 23:36:24.629985 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.26268\n",
            "INFO:tensorflow:loss = 7.020196, step = 100 (79.197 sec)\n",
            "I0623 23:36:24.630998 139948988630912 basic_session_run_hooks.py:260] loss = 7.020196, step = 100 (79.197 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.26664\n",
            "I0623 23:37:43.578805 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.26664\n",
            "INFO:tensorflow:loss = 0.2759923, step = 200 (78.949 sec)\n",
            "I0623 23:37:43.579837 139948988630912 basic_session_run_hooks.py:260] loss = 0.2759923, step = 200 (78.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2355\n",
            "I0623 23:39:04.517458 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.2355\n",
            "INFO:tensorflow:loss = 0.51375365, step = 300 (80.939 sec)\n",
            "I0623 23:39:04.518656 139948988630912 basic_session_run_hooks.py:260] loss = 0.51375365, step = 300 (80.939 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22669\n",
            "I0623 23:40:26.037329 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22669\n",
            "INFO:tensorflow:loss = 0.6428422, step = 400 (81.520 sec)\n",
            "I0623 23:40:26.038535 139948988630912 basic_session_run_hooks.py:260] loss = 0.6428422, step = 400 (81.520 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22259\n",
            "I0623 23:41:47.830918 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22259\n",
            "INFO:tensorflow:loss = 0.6583921, step = 500 (81.793 sec)\n",
            "I0623 23:41:47.831709 139948988630912 basic_session_run_hooks.py:260] loss = 0.6583921, step = 500 (81.793 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.217\n",
            "I0623 23:43:10.000330 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.217\n",
            "INFO:tensorflow:loss = 0.64675945, step = 600 (82.170 sec)\n",
            "I0623 23:43:10.001479 139948988630912 basic_session_run_hooks.py:260] loss = 0.64675945, step = 600 (82.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.21898\n",
            "I0623 23:44:32.036381 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.21898\n",
            "INFO:tensorflow:loss = 0.119932294, step = 700 (82.036 sec)\n",
            "I0623 23:44:32.037375 139948988630912 basic_session_run_hooks.py:260] loss = 0.119932294, step = 700 (82.036 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 717 into training/model.ckpt.\n",
            "I0623 23:44:45.147032 139948988630912 basic_session_run_hooks.py:606] Saving checkpoints for 717 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0623 23:44:47.947685 139948988630912 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0623 23:44:47.951294 139948988630912 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0623 23:44:47.951495 139948988630912 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0623 23:44:47.951598 139948988630912 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0623 23:44:48.925891 139948988630912 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:44:49.164342 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:44:51.792852 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:44:51.907459 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0623 23:44:51.907807 139948988630912 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:44:52.346474 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:44:52.597741 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:44:52.613716 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:44:53.000326 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0623 23:44:53.552059 139948988630912 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0623 23:44:53.725899 139948988630912 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0623 23:44:54.354270 139948988630912 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-06-23T23:44:54Z\n",
            "I0623 23:44:54.368944 139948988630912 evaluation.py:255] Starting evaluation at 2022-06-23T23:44:54Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0623 23:44:55.007241 139948988630912 monitored_session.py:240] Graph was finalized.\n",
            "2022-06-23 23:44:55.008487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:44:55.008936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-06-23 23:44:55.009067: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-23 23:44:55.009103: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-23 23:44:55.009138: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-06-23 23:44:55.009170: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-06-23 23:44:55.009196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-06-23 23:44:55.009226: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-06-23 23:44:55.009256: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-06-23 23:44:55.009356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:44:55.009888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:44:55.010219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-06-23 23:44:55.010270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-06-23 23:44:55.010286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-06-23 23:44:55.010298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-06-23 23:44:55.010407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:44:55.010803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:44:55.011128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-717\n",
            "I0623 23:44:55.012059 139948988630912 saver.py:1284] Restoring parameters from training/model.ckpt-717\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0623 23:44:56.578317 139948988630912 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0623 23:44:56.753885 139948988630912 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 564 images.\n",
            "I0623 23:46:35.439798 139946434746112 coco_evaluation.py:293] Performing evaluation on 564 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0623 23:46:35.441369 139946434746112 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.03s)\n",
            "I0623 23:46:35.473527 139946434746112 coco_tools.py:138] DONE (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.04s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.36s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.069\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.228\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.013\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.089\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.065\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.413\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.483\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.492\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.475\n",
            "INFO:tensorflow:Finished evaluation at 2022-06-23-23:46:38\n",
            "I0623 23:46:38.048404 139948988630912 evaluation.py:275] Finished evaluation at 2022-06-23-23:46:38\n",
            "INFO:tensorflow:Saving dict for global step 717: DetectionBoxes_Precision/mAP = 0.06943848, DetectionBoxes_Precision/mAP (large) = 0.06474129, DetectionBoxes_Precision/mAP (medium) = 0.08920637, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.22766444, DetectionBoxes_Precision/mAP@.75IOU = 0.013194404, DetectionBoxes_Recall/AR@1 = 0.19015747, DetectionBoxes_Recall/AR@10 = 0.41299212, DetectionBoxes_Recall/AR@100 = 0.48346457, DetectionBoxes_Recall/AR@100 (large) = 0.47537315, DetectionBoxes_Recall/AR@100 (medium) = 0.4925, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.07778061, Loss/BoxClassifierLoss/localization_loss = 0.06538094, Loss/RPNLoss/localization_loss = 0.008121706, Loss/RPNLoss/objectness_loss = 0.11920726, Loss/total_loss = 0.27049065, global_step = 717, learning_rate = 0.01, loss = 0.27049065\n",
            "I0623 23:46:38.048715 139948988630912 estimator.py:2049] Saving dict for global step 717: DetectionBoxes_Precision/mAP = 0.06943848, DetectionBoxes_Precision/mAP (large) = 0.06474129, DetectionBoxes_Precision/mAP (medium) = 0.08920637, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.22766444, DetectionBoxes_Precision/mAP@.75IOU = 0.013194404, DetectionBoxes_Recall/AR@1 = 0.19015747, DetectionBoxes_Recall/AR@10 = 0.41299212, DetectionBoxes_Recall/AR@100 = 0.48346457, DetectionBoxes_Recall/AR@100 (large) = 0.47537315, DetectionBoxes_Recall/AR@100 (medium) = 0.4925, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.07778061, Loss/BoxClassifierLoss/localization_loss = 0.06538094, Loss/RPNLoss/localization_loss = 0.008121706, Loss/RPNLoss/objectness_loss = 0.11920726, Loss/total_loss = 0.27049065, global_step = 717, learning_rate = 0.01, loss = 0.27049065\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 717: training/model.ckpt-717\n",
            "I0623 23:46:39.100573 139948988630912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 717: training/model.ckpt-717\n",
            "INFO:tensorflow:global_step/sec: 0.511756\n",
            "I0623 23:47:47.441944 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 0.511756\n",
            "INFO:tensorflow:loss = 0.7373512, step = 800 (195.406 sec)\n",
            "I0623 23:47:47.443064 139948988630912 basic_session_run_hooks.py:260] loss = 0.7373512, step = 800 (195.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22599\n",
            "I0623 23:49:09.008547 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22599\n",
            "INFO:tensorflow:loss = 0.2598911, step = 900 (81.567 sec)\n",
            "I0623 23:49:09.009639 139948988630912 basic_session_run_hooks.py:260] loss = 0.2598911, step = 900 (81.567 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22447\n",
            "I0623 23:50:30.676312 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22447\n",
            "INFO:tensorflow:loss = 0.61246127, step = 1000 (81.668 sec)\n",
            "I0623 23:50:30.677522 139948988630912 basic_session_run_hooks.py:260] loss = 0.61246127, step = 1000 (81.668 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.21745\n",
            "I0623 23:51:52.815308 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.21745\n",
            "INFO:tensorflow:loss = 0.7726324, step = 1100 (82.139 sec)\n",
            "I0623 23:51:52.816370 139948988630912 basic_session_run_hooks.py:260] loss = 0.7726324, step = 1100 (82.139 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22013\n",
            "I0623 23:53:14.774060 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22013\n",
            "INFO:tensorflow:loss = 0.6777789, step = 1200 (81.959 sec)\n",
            "I0623 23:53:14.775394 139948988630912 basic_session_run_hooks.py:260] loss = 0.6777789, step = 1200 (81.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.21712\n",
            "I0623 23:54:36.934915 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.21712\n",
            "INFO:tensorflow:loss = 0.03484897, step = 1300 (82.160 sec)\n",
            "I0623 23:54:36.935736 139948988630912 basic_session_run_hooks.py:260] loss = 0.03484897, step = 1300 (82.160 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1312 into training/model.ckpt.\n",
            "I0623 23:54:45.948529 139948988630912 basic_session_run_hooks.py:606] Saving checkpoints for 1312 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0623 23:54:48.259604 139948988630912 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0623 23:54:48.262290 139948988630912 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0623 23:54:48.262468 139948988630912 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0623 23:54:48.262548 139948988630912 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0623 23:54:48.990393 139948988630912 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:54:49.018667 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:54:51.610769 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:54:51.724825 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0623 23:54:51.725192 139948988630912 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:54:52.158642 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:54:52.755920 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:54:52.771028 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0623 23:54:53.178028 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0623 23:54:54.561387 139948988630912 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-06-23T23:54:54Z\n",
            "I0623 23:54:54.576786 139948988630912 evaluation.py:255] Starting evaluation at 2022-06-23T23:54:54Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0623 23:54:55.209146 139948988630912 monitored_session.py:240] Graph was finalized.\n",
            "2022-06-23 23:54:55.209895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:54:55.210277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-06-23 23:54:55.210450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-23 23:54:55.210488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-23 23:54:55.210518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-06-23 23:54:55.210540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-06-23 23:54:55.210563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-06-23 23:54:55.210589: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-06-23 23:54:55.210616: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-06-23 23:54:55.210712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:54:55.211068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:54:55.211341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-06-23 23:54:55.211384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-06-23 23:54:55.211398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-06-23 23:54:55.211407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-06-23 23:54:55.211520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:54:55.211881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-23 23:54:55.212171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1312\n",
            "I0623 23:54:55.213464 139948988630912 saver.py:1284] Restoring parameters from training/model.ckpt-1312\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0623 23:54:56.810796 139948988630912 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0623 23:54:57.014806 139948988630912 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 564 images.\n",
            "I0623 23:56:36.245539 139946443138816 coco_evaluation.py:293] Performing evaluation on 564 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0623 23:56:36.246544 139946443138816 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.04s)\n",
            "I0623 23:56:36.286789 139946443138816 coco_tools.py:138] DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.01s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.35s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.168\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.020\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.066\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.087\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.424\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.537\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.522\n",
            "INFO:tensorflow:Finished evaluation at 2022-06-23-23:56:38\n",
            "I0623 23:56:38.833219 139948988630912 evaluation.py:275] Finished evaluation at 2022-06-23-23:56:38\n",
            "INFO:tensorflow:Saving dict for global step 1312: DetectionBoxes_Precision/mAP = 0.05413949, DetectionBoxes_Precision/mAP (large) = 0.065966055, DetectionBoxes_Precision/mAP (medium) = 0.06804314, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.16797492, DetectionBoxes_Precision/mAP@.75IOU = 0.019902695, DetectionBoxes_Recall/AR@1 = 0.08740158, DetectionBoxes_Recall/AR@10 = 0.42401576, DetectionBoxes_Recall/AR@100 = 0.52874017, DetectionBoxes_Recall/AR@100 (large) = 0.5216418, DetectionBoxes_Recall/AR@100 (medium) = 0.5366667, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.17858519, Loss/BoxClassifierLoss/localization_loss = 0.045550343, Loss/RPNLoss/localization_loss = 0.010751375, Loss/RPNLoss/objectness_loss = 0.1326244, Loss/total_loss = 0.36751148, global_step = 1312, learning_rate = 0.01, loss = 0.36751148\n",
            "I0623 23:56:38.833503 139948988630912 estimator.py:2049] Saving dict for global step 1312: DetectionBoxes_Precision/mAP = 0.05413949, DetectionBoxes_Precision/mAP (large) = 0.065966055, DetectionBoxes_Precision/mAP (medium) = 0.06804314, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.16797492, DetectionBoxes_Precision/mAP@.75IOU = 0.019902695, DetectionBoxes_Recall/AR@1 = 0.08740158, DetectionBoxes_Recall/AR@10 = 0.42401576, DetectionBoxes_Recall/AR@100 = 0.52874017, DetectionBoxes_Recall/AR@100 (large) = 0.5216418, DetectionBoxes_Recall/AR@100 (medium) = 0.5366667, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.17858519, Loss/BoxClassifierLoss/localization_loss = 0.045550343, Loss/RPNLoss/localization_loss = 0.010751375, Loss/RPNLoss/objectness_loss = 0.1326244, Loss/total_loss = 0.36751148, global_step = 1312, learning_rate = 0.01, loss = 0.36751148\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1312: training/model.ckpt-1312\n",
            "I0623 23:56:38.841847 139948988630912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1312: training/model.ckpt-1312\n",
            "INFO:tensorflow:global_step/sec: 0.514137\n",
            "I0623 23:57:51.435557 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 0.514137\n",
            "INFO:tensorflow:loss = 0.6223301, step = 1400 (194.501 sec)\n",
            "I0623 23:57:51.436648 139948988630912 basic_session_run_hooks.py:260] loss = 0.6223301, step = 1400 (194.501 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22421\n",
            "I0623 23:59:13.120586 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22421\n",
            "INFO:tensorflow:loss = 0.30646747, step = 1500 (81.685 sec)\n",
            "I0623 23:59:13.121844 139948988630912 basic_session_run_hooks.py:260] loss = 0.30646747, step = 1500 (81.685 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22429\n",
            "I0624 00:00:34.800270 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22429\n",
            "INFO:tensorflow:loss = 0.0024992123, step = 1600 (81.680 sec)\n",
            "I0624 00:00:34.801467 139948988630912 basic_session_run_hooks.py:260] loss = 0.0024992123, step = 1600 (81.680 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22674\n",
            "I0624 00:01:56.317441 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22674\n",
            "INFO:tensorflow:loss = 0.37832156, step = 1700 (81.517 sec)\n",
            "I0624 00:01:56.318738 139948988630912 basic_session_run_hooks.py:260] loss = 0.37832156, step = 1700 (81.517 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22549\n",
            "I0624 00:03:17.917507 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22549\n",
            "INFO:tensorflow:loss = 0.09393474, step = 1800 (81.600 sec)\n",
            "I0624 00:03:17.918644 139948988630912 basic_session_run_hooks.py:260] loss = 0.09393474, step = 1800 (81.600 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22334\n",
            "I0624 00:04:39.660919 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22334\n",
            "INFO:tensorflow:loss = 0.23555022, step = 1900 (81.743 sec)\n",
            "I0624 00:04:39.662072 139948988630912 basic_session_run_hooks.py:260] loss = 0.23555022, step = 1900 (81.743 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1909 into training/model.ckpt.\n",
            "I0624 00:04:46.316627 139948988630912 basic_session_run_hooks.py:606] Saving checkpoints for 1909 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0624 00:04:48.926142 139948988630912 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0624 00:04:48.928765 139948988630912 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0624 00:04:48.928955 139948988630912 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0624 00:04:48.929037 139948988630912 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0624 00:04:49.655668 139948988630912 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:04:49.683180 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:04:52.273030 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:04:52.390817 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0624 00:04:52.391218 139948988630912 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:04:52.846036 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:04:53.114395 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:04:53.132682 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:04:53.513713 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0624 00:04:54.827640 139948988630912 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-06-24T00:04:54Z\n",
            "I0624 00:04:54.843425 139948988630912 evaluation.py:255] Starting evaluation at 2022-06-24T00:04:54Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0624 00:04:55.506779 139948988630912 monitored_session.py:240] Graph was finalized.\n",
            "2022-06-24 00:04:55.507437: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:04:55.507809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-06-24 00:04:55.507926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-24 00:04:55.507963: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-24 00:04:55.507992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-06-24 00:04:55.508016: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-06-24 00:04:55.508041: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-06-24 00:04:55.508067: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-06-24 00:04:55.508095: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-06-24 00:04:55.508188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:04:55.508569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:04:55.508845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-06-24 00:04:55.508893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-06-24 00:04:55.508907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-06-24 00:04:55.508927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-06-24 00:04:55.509037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:04:55.509367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:04:55.509661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1909\n",
            "I0624 00:04:55.510668 139948988630912 saver.py:1284] Restoring parameters from training/model.ckpt-1909\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0624 00:04:57.043940 139948988630912 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0624 00:04:57.226149 139948988630912 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 564 images.\n",
            "I0624 00:06:31.266342 139946434746112 coco_evaluation.py:293] Performing evaluation on 564 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0624 00:06:31.267311 139946434746112 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.04s)\n",
            "I0624 00:06:31.306453 139946434746112 coco_tools.py:138] DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.98s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.34s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.745\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.190\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.327\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.478\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.546\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.559\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.552\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.565\n",
            "INFO:tensorflow:Finished evaluation at 2022-06-24-00:06:33\n",
            "I0624 00:06:33.822727 139948988630912 evaluation.py:275] Finished evaluation at 2022-06-24-00:06:33\n",
            "INFO:tensorflow:Saving dict for global step 1909: DetectionBoxes_Precision/mAP = 0.36475852, DetectionBoxes_Precision/mAP (large) = 0.3268836, DetectionBoxes_Precision/mAP (medium) = 0.4077464, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.74529135, DetectionBoxes_Precision/mAP@.75IOU = 0.1899138, DetectionBoxes_Recall/AR@1 = 0.47795275, DetectionBoxes_Recall/AR@10 = 0.546063, DetectionBoxes_Recall/AR@100 = 0.5586614, DetectionBoxes_Recall/AR@100 (large) = 0.5649254, DetectionBoxes_Recall/AR@100 (medium) = 0.5516667, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.050264634, Loss/BoxClassifierLoss/localization_loss = 0.04143765, Loss/RPNLoss/localization_loss = 0.0048052366, Loss/RPNLoss/objectness_loss = 0.1285378, Loss/total_loss = 0.22504528, global_step = 1909, learning_rate = 0.005, loss = 0.22504528\n",
            "I0624 00:06:33.823000 139948988630912 estimator.py:2049] Saving dict for global step 1909: DetectionBoxes_Precision/mAP = 0.36475852, DetectionBoxes_Precision/mAP (large) = 0.3268836, DetectionBoxes_Precision/mAP (medium) = 0.4077464, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.74529135, DetectionBoxes_Precision/mAP@.75IOU = 0.1899138, DetectionBoxes_Recall/AR@1 = 0.47795275, DetectionBoxes_Recall/AR@10 = 0.546063, DetectionBoxes_Recall/AR@100 = 0.5586614, DetectionBoxes_Recall/AR@100 (large) = 0.5649254, DetectionBoxes_Recall/AR@100 (medium) = 0.5516667, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.050264634, Loss/BoxClassifierLoss/localization_loss = 0.04143765, Loss/RPNLoss/localization_loss = 0.0048052366, Loss/RPNLoss/objectness_loss = 0.1285378, Loss/total_loss = 0.22504528, global_step = 1909, learning_rate = 0.005, loss = 0.22504528\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1909: training/model.ckpt-1909\n",
            "I0624 00:06:33.831546 139948988630912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1909: training/model.ckpt-1909\n",
            "INFO:tensorflow:global_step/sec: 0.529174\n",
            "I0624 00:07:48.634654 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 0.529174\n",
            "INFO:tensorflow:loss = 0.29874292, step = 2000 (188.974 sec)\n",
            "I0624 00:07:48.635871 139948988630912 basic_session_run_hooks.py:260] loss = 0.29874292, step = 2000 (188.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22917\n",
            "I0624 00:09:09.990241 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22917\n",
            "INFO:tensorflow:loss = 0.13082694, step = 2100 (81.355 sec)\n",
            "I0624 00:09:09.991199 139948988630912 basic_session_run_hooks.py:260] loss = 0.13082694, step = 2100 (81.355 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22181\n",
            "I0624 00:10:31.836266 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22181\n",
            "INFO:tensorflow:loss = 0.21774979, step = 2200 (81.846 sec)\n",
            "I0624 00:10:31.837278 139948988630912 basic_session_run_hooks.py:260] loss = 0.21774979, step = 2200 (81.846 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22332\n",
            "I0624 00:11:53.581105 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22332\n",
            "INFO:tensorflow:loss = 0.16051874, step = 2300 (81.745 sec)\n",
            "I0624 00:11:53.581996 139948988630912 basic_session_run_hooks.py:260] loss = 0.16051874, step = 2300 (81.745 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.21985\n",
            "I0624 00:13:15.558737 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.21985\n",
            "INFO:tensorflow:loss = 0.099517316, step = 2400 (81.978 sec)\n",
            "I0624 00:13:15.559832 139948988630912 basic_session_run_hooks.py:260] loss = 0.099517316, step = 2400 (81.978 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22654\n",
            "I0624 00:14:37.089183 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22654\n",
            "INFO:tensorflow:loss = 0.08751052, step = 2500 (81.530 sec)\n",
            "I0624 00:14:37.090062 139948988630912 basic_session_run_hooks.py:260] loss = 0.08751052, step = 2500 (81.530 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2513 into training/model.ckpt.\n",
            "I0624 00:14:46.899928 139948988630912 basic_session_run_hooks.py:606] Saving checkpoints for 2513 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0624 00:14:49.210021 139948988630912 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0624 00:14:49.212672 139948988630912 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0624 00:14:49.212833 139948988630912 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0624 00:14:49.212916 139948988630912 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0624 00:14:49.949007 139948988630912 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:14:49.977846 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:14:52.535544 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:14:52.655837 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0624 00:14:52.656189 139948988630912 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:14:53.091807 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:14:53.682727 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:14:53.697341 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:14:54.082072 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0624 00:14:55.405895 139948988630912 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-06-24T00:14:55Z\n",
            "I0624 00:14:55.420701 139948988630912 evaluation.py:255] Starting evaluation at 2022-06-24T00:14:55Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0624 00:14:56.052087 139948988630912 monitored_session.py:240] Graph was finalized.\n",
            "2022-06-24 00:14:56.052732: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:14:56.053112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-06-24 00:14:56.053205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-24 00:14:56.053231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-24 00:14:56.053255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-06-24 00:14:56.053279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-06-24 00:14:56.053314: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-06-24 00:14:56.053343: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-06-24 00:14:56.053371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-06-24 00:14:56.053483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:14:56.053829: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:14:56.054106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-06-24 00:14:56.054145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-06-24 00:14:56.054158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-06-24 00:14:56.054170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-06-24 00:14:56.054340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:14:56.054700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:14:56.054988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-2513\n",
            "I0624 00:14:56.056193 139948988630912 saver.py:1284] Restoring parameters from training/model.ckpt-2513\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0624 00:14:57.630884 139948988630912 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0624 00:14:57.827499 139948988630912 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 564 images.\n",
            "I0624 00:16:33.063858 139946434746112 coco_evaluation.py:293] Performing evaluation on 564 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0624 00:16:33.064837 139946434746112 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.04s)\n",
            "I0624 00:16:33.103444 139946434746112 coco_tools.py:138] DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.23s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.37s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.424\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.863\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.292\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.461\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.521\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.560\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.571\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.570\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.572\n",
            "INFO:tensorflow:Finished evaluation at 2022-06-24-00:16:35\n",
            "I0624 00:16:35.890507 139948988630912 evaluation.py:275] Finished evaluation at 2022-06-24-00:16:35\n",
            "INFO:tensorflow:Saving dict for global step 2513: DetectionBoxes_Precision/mAP = 0.42420954, DetectionBoxes_Precision/mAP (large) = 0.46091223, DetectionBoxes_Precision/mAP (medium) = 0.4266497, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.8631439, DetectionBoxes_Precision/mAP@.75IOU = 0.29195458, DetectionBoxes_Recall/AR@1 = 0.52086616, DetectionBoxes_Recall/AR@10 = 0.5598425, DetectionBoxes_Recall/AR@100 = 0.57125986, DetectionBoxes_Recall/AR@100 (large) = 0.57238805, DetectionBoxes_Recall/AR@100 (medium) = 0.57, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.054315973, Loss/BoxClassifierLoss/localization_loss = 0.030588213, Loss/RPNLoss/localization_loss = 0.0047399686, Loss/RPNLoss/objectness_loss = 0.13198675, Loss/total_loss = 0.22163115, global_step = 2513, learning_rate = 1e-04, loss = 0.22163115\n",
            "I0624 00:16:35.890767 139948988630912 estimator.py:2049] Saving dict for global step 2513: DetectionBoxes_Precision/mAP = 0.42420954, DetectionBoxes_Precision/mAP (large) = 0.46091223, DetectionBoxes_Precision/mAP (medium) = 0.4266497, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.8631439, DetectionBoxes_Precision/mAP@.75IOU = 0.29195458, DetectionBoxes_Recall/AR@1 = 0.52086616, DetectionBoxes_Recall/AR@10 = 0.5598425, DetectionBoxes_Recall/AR@100 = 0.57125986, DetectionBoxes_Recall/AR@100 (large) = 0.57238805, DetectionBoxes_Recall/AR@100 (medium) = 0.57, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.054315973, Loss/BoxClassifierLoss/localization_loss = 0.030588213, Loss/RPNLoss/localization_loss = 0.0047399686, Loss/RPNLoss/objectness_loss = 0.13198675, Loss/total_loss = 0.22163115, global_step = 2513, learning_rate = 1e-04, loss = 0.22163115\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2513: training/model.ckpt-2513\n",
            "I0624 00:16:35.899104 139948988630912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 2513: training/model.ckpt-2513\n",
            "INFO:tensorflow:global_step/sec: 0.525075\n",
            "I0624 00:17:47.538151 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 0.525075\n",
            "INFO:tensorflow:loss = 0.19285165, step = 2600 (190.449 sec)\n",
            "I0624 00:17:47.539087 139948988630912 basic_session_run_hooks.py:260] loss = 0.19285165, step = 2600 (190.449 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22518\n",
            "I0624 00:19:09.158612 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22518\n",
            "INFO:tensorflow:loss = 0.26036087, step = 2700 (81.621 sec)\n",
            "I0624 00:19:09.159620 139948988630912 basic_session_run_hooks.py:260] loss = 0.26036087, step = 2700 (81.621 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.20776\n",
            "I0624 00:20:31.956253 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.20776\n",
            "INFO:tensorflow:loss = 0.3747283, step = 2800 (82.798 sec)\n",
            "I0624 00:20:31.957395 139948988630912 basic_session_run_hooks.py:260] loss = 0.3747283, step = 2800 (82.798 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.20237\n",
            "I0624 00:21:55.125221 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.20237\n",
            "INFO:tensorflow:loss = 0.12008111, step = 2900 (83.169 sec)\n",
            "I0624 00:21:55.126345 139948988630912 basic_session_run_hooks.py:260] loss = 0.12008111, step = 2900 (83.169 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.20559\n",
            "I0624 00:23:18.072308 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.20559\n",
            "INFO:tensorflow:loss = 0.05493617, step = 3000 (82.947 sec)\n",
            "I0624 00:23:18.073180 139948988630912 basic_session_run_hooks.py:260] loss = 0.05493617, step = 3000 (82.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.20382\n",
            "I0624 00:24:41.141185 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.20382\n",
            "INFO:tensorflow:loss = 0.13046513, step = 3100 (83.069 sec)\n",
            "I0624 00:24:41.142215 139948988630912 basic_session_run_hooks.py:260] loss = 0.13046513, step = 3100 (83.069 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3108 into training/model.ckpt.\n",
            "I0624 00:24:46.958145 139948988630912 basic_session_run_hooks.py:606] Saving checkpoints for 3108 into training/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0624 00:24:47.996690 139948988630912 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0624 00:24:49.246336 139948988630912 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0624 00:24:49.248814 139948988630912 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0624 00:24:49.249005 139948988630912 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0624 00:24:49.249087 139948988630912 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0624 00:24:49.986216 139948988630912 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:24:50.014748 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:24:52.658004 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:24:52.770538 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0624 00:24:52.770894 139948988630912 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:24:53.202750 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:24:53.450232 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:24:53.466382 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:24:53.851360 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0624 00:24:55.208495 139948988630912 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-06-24T00:24:55Z\n",
            "I0624 00:24:55.223265 139948988630912 evaluation.py:255] Starting evaluation at 2022-06-24T00:24:55Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0624 00:24:55.853954 139948988630912 monitored_session.py:240] Graph was finalized.\n",
            "2022-06-24 00:24:55.854727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:24:55.855219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-06-24 00:24:55.855348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-24 00:24:55.855377: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-24 00:24:55.855398: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-06-24 00:24:55.855438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-06-24 00:24:55.855479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-06-24 00:24:55.855500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-06-24 00:24:55.855519: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-06-24 00:24:55.855633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:24:55.856153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:24:55.856572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-06-24 00:24:55.856631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-06-24 00:24:55.856650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-06-24 00:24:55.856663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-06-24 00:24:55.856785: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:24:55.857154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:24:55.857456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-3108\n",
            "I0624 00:24:55.858391 139948988630912 saver.py:1284] Restoring parameters from training/model.ckpt-3108\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0624 00:24:57.393073 139948988630912 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0624 00:24:57.576866 139948988630912 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 564 images.\n",
            "I0624 00:26:34.455697 139946443138816 coco_evaluation.py:293] Performing evaluation on 564 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0624 00:26:34.457491 139946443138816 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.04s)\n",
            "I0624 00:26:34.497083 139946443138816 coco_tools.py:138] DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.95s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.34s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.631\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.962\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.775\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.669\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.611\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.671\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.695\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.702\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.737\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.670\n",
            "INFO:tensorflow:Finished evaluation at 2022-06-24-00:26:36\n",
            "I0624 00:26:36.987081 139948988630912 evaluation.py:275] Finished evaluation at 2022-06-24-00:26:36\n",
            "INFO:tensorflow:Saving dict for global step 3108: DetectionBoxes_Precision/mAP = 0.6309114, DetectionBoxes_Precision/mAP (large) = 0.6105323, DetectionBoxes_Precision/mAP (medium) = 0.6694497, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9623076, DetectionBoxes_Precision/mAP@.75IOU = 0.7751431, DetectionBoxes_Recall/AR@1 = 0.6712598, DetectionBoxes_Recall/AR@10 = 0.6948819, DetectionBoxes_Recall/AR@100 = 0.7015748, DetectionBoxes_Recall/AR@100 (large) = 0.67014927, DetectionBoxes_Recall/AR@100 (medium) = 0.7366667, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.029888302, Loss/BoxClassifierLoss/localization_loss = 0.014601544, Loss/RPNLoss/localization_loss = 0.0038481457, Loss/RPNLoss/objectness_loss = 0.12684415, Loss/total_loss = 0.17518222, global_step = 3108, learning_rate = 1e-04, loss = 0.17518222\n",
            "I0624 00:26:36.987336 139948988630912 estimator.py:2049] Saving dict for global step 3108: DetectionBoxes_Precision/mAP = 0.6309114, DetectionBoxes_Precision/mAP (large) = 0.6105323, DetectionBoxes_Precision/mAP (medium) = 0.6694497, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9623076, DetectionBoxes_Precision/mAP@.75IOU = 0.7751431, DetectionBoxes_Recall/AR@1 = 0.6712598, DetectionBoxes_Recall/AR@10 = 0.6948819, DetectionBoxes_Recall/AR@100 = 0.7015748, DetectionBoxes_Recall/AR@100 (large) = 0.67014927, DetectionBoxes_Recall/AR@100 (medium) = 0.7366667, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.029888302, Loss/BoxClassifierLoss/localization_loss = 0.014601544, Loss/RPNLoss/localization_loss = 0.0038481457, Loss/RPNLoss/objectness_loss = 0.12684415, Loss/total_loss = 0.17518222, global_step = 3108, learning_rate = 1e-04, loss = 0.17518222\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3108: training/model.ckpt-3108\n",
            "I0624 00:26:36.995833 139948988630912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3108: training/model.ckpt-3108\n",
            "INFO:tensorflow:global_step/sec: 0.516998\n",
            "I0624 00:27:54.565535 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 0.516998\n",
            "INFO:tensorflow:loss = 0.13750581, step = 3200 (193.424 sec)\n",
            "I0624 00:27:54.566456 139948988630912 basic_session_run_hooks.py:260] loss = 0.13750581, step = 3200 (193.424 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2065\n",
            "I0624 00:29:17.450190 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.2065\n",
            "INFO:tensorflow:loss = 0.0634778, step = 3300 (82.885 sec)\n",
            "I0624 00:29:17.451223 139948988630912 basic_session_run_hooks.py:260] loss = 0.0634778, step = 3300 (82.885 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.20461\n",
            "I0624 00:30:40.464497 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.20461\n",
            "INFO:tensorflow:loss = 0.24759746, step = 3400 (83.014 sec)\n",
            "I0624 00:30:40.465589 139948988630912 basic_session_run_hooks.py:260] loss = 0.24759746, step = 3400 (83.014 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2057\n",
            "I0624 00:32:03.403897 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.2057\n",
            "INFO:tensorflow:loss = 0.073797815, step = 3500 (82.939 sec)\n",
            "I0624 00:32:03.404707 139948988630912 basic_session_run_hooks.py:260] loss = 0.073797815, step = 3500 (82.939 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.2046\n",
            "I0624 00:33:26.418915 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.2046\n",
            "INFO:tensorflow:loss = 0.060520817, step = 3600 (83.015 sec)\n",
            "I0624 00:33:26.420005 139948988630912 basic_session_run_hooks.py:260] loss = 0.060520817, step = 3600 (83.015 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3699 into training/model.ckpt.\n",
            "I0624 00:34:47.602341 139948988630912 basic_session_run_hooks.py:606] Saving checkpoints for 3699 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0624 00:34:50.048997 139948988630912 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0624 00:34:50.051632 139948988630912 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0624 00:34:50.051799 139948988630912 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0624 00:34:50.051878 139948988630912 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0624 00:34:50.804219 139948988630912 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:34:50.833535 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:34:53.486889 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:34:53.601182 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0624 00:34:53.601581 139948988630912 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:34:54.038342 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:34:54.299389 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:34:54.314599 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:34:54.693351 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0624 00:34:56.036305 139948988630912 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-06-24T00:34:56Z\n",
            "I0624 00:34:56.051892 139948988630912 evaluation.py:255] Starting evaluation at 2022-06-24T00:34:56Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0624 00:34:56.689276 139948988630912 monitored_session.py:240] Graph was finalized.\n",
            "2022-06-24 00:34:56.689941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:34:56.690315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-06-24 00:34:56.690409: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-24 00:34:56.690456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-24 00:34:56.690484: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-06-24 00:34:56.690508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-06-24 00:34:56.690531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-06-24 00:34:56.690553: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-06-24 00:34:56.690575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-06-24 00:34:56.690664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:34:56.691020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:34:56.691293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-06-24 00:34:56.691334: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-06-24 00:34:56.691348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-06-24 00:34:56.691357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-06-24 00:34:56.691463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:34:56.691789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:34:56.692082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-3699\n",
            "I0624 00:34:56.693134 139948988630912 saver.py:1284] Restoring parameters from training/model.ckpt-3699\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0624 00:34:58.232249 139948988630912 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0624 00:34:58.430107 139948988630912 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 564 images.\n",
            "I0624 00:36:35.944187 139946443138816 coco_evaluation.py:293] Performing evaluation on 564 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0624 00:36:35.945429 139946443138816 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.04s)\n",
            "I0624 00:36:35.986087 139946443138816 coco_tools.py:138] DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.92s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.34s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.966\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.858\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.704\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.710\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.730\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.735\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.761\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.713\n",
            "INFO:tensorflow:Finished evaluation at 2022-06-24-00:36:38\n",
            "I0624 00:36:38.440668 139948988630912 evaluation.py:275] Finished evaluation at 2022-06-24-00:36:38\n",
            "INFO:tensorflow:Saving dict for global step 3699: DetectionBoxes_Precision/mAP = 0.66633624, DetectionBoxes_Precision/mAP (large) = 0.6467906, DetectionBoxes_Precision/mAP (medium) = 0.7044987, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9664544, DetectionBoxes_Precision/mAP@.75IOU = 0.8577217, DetectionBoxes_Recall/AR@1 = 0.7102362, DetectionBoxes_Recall/AR@10 = 0.72952753, DetectionBoxes_Recall/AR@100 = 0.73543304, DetectionBoxes_Recall/AR@100 (large) = 0.71268654, DetectionBoxes_Recall/AR@100 (medium) = 0.7608333, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.029625071, Loss/BoxClassifierLoss/localization_loss = 0.01245371, Loss/RPNLoss/localization_loss = 0.003589302, Loss/RPNLoss/objectness_loss = 0.12768973, Loss/total_loss = 0.17335787, global_step = 3699, learning_rate = 1e-04, loss = 0.17335787\n",
            "I0624 00:36:38.440925 139948988630912 estimator.py:2049] Saving dict for global step 3699: DetectionBoxes_Precision/mAP = 0.66633624, DetectionBoxes_Precision/mAP (large) = 0.6467906, DetectionBoxes_Precision/mAP (medium) = 0.7044987, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9664544, DetectionBoxes_Precision/mAP@.75IOU = 0.8577217, DetectionBoxes_Recall/AR@1 = 0.7102362, DetectionBoxes_Recall/AR@10 = 0.72952753, DetectionBoxes_Recall/AR@100 = 0.73543304, DetectionBoxes_Recall/AR@100 (large) = 0.71268654, DetectionBoxes_Recall/AR@100 (medium) = 0.7608333, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.029625071, Loss/BoxClassifierLoss/localization_loss = 0.01245371, Loss/RPNLoss/localization_loss = 0.003589302, Loss/RPNLoss/objectness_loss = 0.12768973, Loss/total_loss = 0.17335787, global_step = 3699, learning_rate = 1e-04, loss = 0.17335787\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3699: training/model.ckpt-3699\n",
            "I0624 00:36:38.449035 139948988630912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3699: training/model.ckpt-3699\n",
            "INFO:tensorflow:global_step/sec: 0.516134\n",
            "I0624 00:36:40.167061 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 0.516134\n",
            "INFO:tensorflow:loss = 0.005290725, step = 3700 (193.748 sec)\n",
            "I0624 00:36:40.168303 139948988630912 basic_session_run_hooks.py:260] loss = 0.005290725, step = 3700 (193.748 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.20612\n",
            "I0624 00:38:03.077548 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.20612\n",
            "INFO:tensorflow:loss = 0.51028377, step = 3800 (82.911 sec)\n",
            "I0624 00:38:03.078956 139948988630912 basic_session_run_hooks.py:260] loss = 0.51028377, step = 3800 (82.911 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.20447\n",
            "I0624 00:39:26.101682 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.20447\n",
            "INFO:tensorflow:loss = 0.062755294, step = 3900 (83.024 sec)\n",
            "I0624 00:39:26.102774 139948988630912 basic_session_run_hooks.py:260] loss = 0.062755294, step = 3900 (83.024 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.20818\n",
            "I0624 00:40:48.870737 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.20818\n",
            "INFO:tensorflow:loss = 0.11027499, step = 4000 (82.769 sec)\n",
            "I0624 00:40:48.871879 139948988630912 basic_session_run_hooks.py:260] loss = 0.11027499, step = 4000 (82.769 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.21342\n",
            "I0624 00:42:11.282397 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.21342\n",
            "INFO:tensorflow:loss = 0.12423441, step = 4100 (82.412 sec)\n",
            "I0624 00:42:11.283514 139948988630912 basic_session_run_hooks.py:260] loss = 0.12423441, step = 4100 (82.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22065\n",
            "I0624 00:43:33.206016 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22065\n",
            "INFO:tensorflow:loss = 0.023074511, step = 4200 (81.924 sec)\n",
            "I0624 00:43:33.207047 139948988630912 basic_session_run_hooks.py:260] loss = 0.023074511, step = 4200 (81.924 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4292 into training/model.ckpt.\n",
            "I0624 00:44:48.067296 139948988630912 basic_session_run_hooks.py:606] Saving checkpoints for 4292 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0624 00:44:50.518390 139948988630912 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0624 00:44:50.520743 139948988630912 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0624 00:44:50.520915 139948988630912 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0624 00:44:50.520999 139948988630912 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0624 00:44:51.259990 139948988630912 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:44:51.289949 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:44:53.937999 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:44:54.050194 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0624 00:44:54.050554 139948988630912 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:44:54.492187 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:44:54.738995 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:44:54.753732 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:44:55.485668 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0624 00:44:56.841835 139948988630912 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-06-24T00:44:56Z\n",
            "I0624 00:44:56.857796 139948988630912 evaluation.py:255] Starting evaluation at 2022-06-24T00:44:56Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0624 00:44:57.481794 139948988630912 monitored_session.py:240] Graph was finalized.\n",
            "2022-06-24 00:44:57.482459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:44:57.482855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-06-24 00:44:57.482965: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-24 00:44:57.482995: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-24 00:44:57.483024: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-06-24 00:44:57.483048: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-06-24 00:44:57.483072: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-06-24 00:44:57.483098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-06-24 00:44:57.483125: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-06-24 00:44:57.483216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:44:57.483596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:44:57.483884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-06-24 00:44:57.483937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-06-24 00:44:57.483953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-06-24 00:44:57.483966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-06-24 00:44:57.484133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:44:57.484493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:44:57.484782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-4292\n",
            "I0624 00:44:57.485886 139948988630912 saver.py:1284] Restoring parameters from training/model.ckpt-4292\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0624 00:44:59.135452 139948988630912 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0624 00:44:59.344556 139948988630912 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 564 images.\n",
            "I0624 00:46:32.941022 139946443138816 coco_evaluation.py:293] Performing evaluation on 564 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0624 00:46:32.942761 139946443138816 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.04s)\n",
            "I0624 00:46:32.985543 139946443138816 coco_tools.py:138] DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.94s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.35s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.691\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.970\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.872\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.738\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.660\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.730\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.751\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.757\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.795\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.723\n",
            "INFO:tensorflow:Finished evaluation at 2022-06-24-00:46:35\n",
            "I0624 00:46:35.466406 139948988630912 evaluation.py:275] Finished evaluation at 2022-06-24-00:46:35\n",
            "INFO:tensorflow:Saving dict for global step 4292: DetectionBoxes_Precision/mAP = 0.69105387, DetectionBoxes_Precision/mAP (large) = 0.6596428, DetectionBoxes_Precision/mAP (medium) = 0.7377696, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.969548, DetectionBoxes_Precision/mAP@.75IOU = 0.8715819, DetectionBoxes_Recall/AR@1 = 0.7299213, DetectionBoxes_Recall/AR@10 = 0.7511811, DetectionBoxes_Recall/AR@100 = 0.75708663, DetectionBoxes_Recall/AR@100 (large) = 0.72313434, DetectionBoxes_Recall/AR@100 (medium) = 0.795, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.02710567, Loss/BoxClassifierLoss/localization_loss = 0.011489135, Loss/RPNLoss/localization_loss = 0.0034657458, Loss/RPNLoss/objectness_loss = 0.1279065, Loss/total_loss = 0.16996704, global_step = 4292, learning_rate = 1e-04, loss = 0.16996704\n",
            "I0624 00:46:35.466719 139948988630912 estimator.py:2049] Saving dict for global step 4292: DetectionBoxes_Precision/mAP = 0.69105387, DetectionBoxes_Precision/mAP (large) = 0.6596428, DetectionBoxes_Precision/mAP (medium) = 0.7377696, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.969548, DetectionBoxes_Precision/mAP@.75IOU = 0.8715819, DetectionBoxes_Recall/AR@1 = 0.7299213, DetectionBoxes_Recall/AR@10 = 0.7511811, DetectionBoxes_Recall/AR@100 = 0.75708663, DetectionBoxes_Recall/AR@100 (large) = 0.72313434, DetectionBoxes_Recall/AR@100 (medium) = 0.795, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.02710567, Loss/BoxClassifierLoss/localization_loss = 0.011489135, Loss/RPNLoss/localization_loss = 0.0034657458, Loss/RPNLoss/objectness_loss = 0.1279065, Loss/total_loss = 0.16996704, global_step = 4292, learning_rate = 1e-04, loss = 0.16996704\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4292: training/model.ckpt-4292\n",
            "I0624 00:46:35.474836 139948988630912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 4292: training/model.ckpt-4292\n",
            "INFO:tensorflow:global_step/sec: 0.527289\n",
            "I0624 00:46:42.855256 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 0.527289\n",
            "INFO:tensorflow:loss = 0.078803204, step = 4300 (189.649 sec)\n",
            "I0624 00:46:42.856515 139948988630912 basic_session_run_hooks.py:260] loss = 0.078803204, step = 4300 (189.649 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22868\n",
            "I0624 00:48:04.243211 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22868\n",
            "INFO:tensorflow:loss = 0.21893078, step = 4400 (81.388 sec)\n",
            "I0624 00:48:04.244217 139948988630912 basic_session_run_hooks.py:260] loss = 0.21893078, step = 4400 (81.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22723\n",
            "I0624 00:49:25.727848 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22723\n",
            "INFO:tensorflow:loss = 0.12994738, step = 4500 (81.485 sec)\n",
            "I0624 00:49:25.728759 139948988630912 basic_session_run_hooks.py:260] loss = 0.12994738, step = 4500 (81.485 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22267\n",
            "I0624 00:50:47.515995 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22267\n",
            "INFO:tensorflow:loss = 0.04173285, step = 4600 (81.788 sec)\n",
            "I0624 00:50:47.517067 139948988630912 basic_session_run_hooks.py:260] loss = 0.04173285, step = 4600 (81.788 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22432\n",
            "I0624 00:52:09.193772 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22432\n",
            "INFO:tensorflow:loss = 0.03056888, step = 4700 (81.678 sec)\n",
            "I0624 00:52:09.194759 139948988630912 basic_session_run_hooks.py:260] loss = 0.03056888, step = 4700 (81.678 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.22574\n",
            "I0624 00:53:30.777201 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 1.22574\n",
            "INFO:tensorflow:loss = 0.097266175, step = 4800 (81.583 sec)\n",
            "I0624 00:53:30.778214 139948988630912 basic_session_run_hooks.py:260] loss = 0.097266175, step = 4800 (81.583 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4896 into training/model.ckpt.\n",
            "I0624 00:54:48.573653 139948988630912 basic_session_run_hooks.py:606] Saving checkpoints for 4896 into training/model.ckpt.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0624 00:54:50.977463 139948988630912 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0624 00:54:50.979683 139948988630912 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0624 00:54:50.979830 139948988630912 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0624 00:54:50.979906 139948988630912 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0624 00:54:52.025789 139948988630912 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:54:52.054937 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:54:54.675983 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:54:54.786469 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0624 00:54:54.786830 139948988630912 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:54:55.214162 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:54:55.455644 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:54:55.469736 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:54:55.837831 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0624 00:54:57.157497 139948988630912 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-06-24T00:54:57Z\n",
            "I0624 00:54:57.178459 139948988630912 evaluation.py:255] Starting evaluation at 2022-06-24T00:54:57Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0624 00:54:57.807175 139948988630912 monitored_session.py:240] Graph was finalized.\n",
            "2022-06-24 00:54:57.807868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:54:57.808236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-06-24 00:54:57.808333: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-24 00:54:57.808361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-24 00:54:57.808385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-06-24 00:54:57.808409: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-06-24 00:54:57.808454: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-06-24 00:54:57.808481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-06-24 00:54:57.808504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-06-24 00:54:57.808602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:54:57.808961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:54:57.809258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-06-24 00:54:57.809309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-06-24 00:54:57.809320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-06-24 00:54:57.809329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-06-24 00:54:57.809488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:54:57.809956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:54:57.810362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-4896\n",
            "I0624 00:54:57.811635 139948988630912 saver.py:1284] Restoring parameters from training/model.ckpt-4896\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0624 00:54:59.426496 139948988630912 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0624 00:54:59.620266 139948988630912 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 564 images.\n",
            "I0624 00:56:33.588904 139946434746112 coco_evaluation.py:293] Performing evaluation on 564 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0624 00:56:33.590365 139946434746112 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.04s)\n",
            "I0624 00:56:33.633824 139946434746112 coco_tools.py:138] DONE (t=0.04s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.93s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.34s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.698\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.973\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.881\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.740\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.671\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.737\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.756\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.759\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.795\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.727\n",
            "INFO:tensorflow:Finished evaluation at 2022-06-24-00:56:36\n",
            "I0624 00:56:36.097608 139948988630912 evaluation.py:275] Finished evaluation at 2022-06-24-00:56:36\n",
            "INFO:tensorflow:Saving dict for global step 4896: DetectionBoxes_Precision/mAP = 0.697726, DetectionBoxes_Precision/mAP (large) = 0.67134786, DetectionBoxes_Precision/mAP (medium) = 0.74019545, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9732262, DetectionBoxes_Precision/mAP@.75IOU = 0.881411, DetectionBoxes_Recall/AR@1 = 0.73661417, DetectionBoxes_Recall/AR@10 = 0.7559055, DetectionBoxes_Recall/AR@100 = 0.75905514, DetectionBoxes_Recall/AR@100 (large) = 0.72686565, DetectionBoxes_Recall/AR@100 (medium) = 0.795, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.028203804, Loss/BoxClassifierLoss/localization_loss = 0.010833929, Loss/RPNLoss/localization_loss = 0.0033976466, Loss/RPNLoss/objectness_loss = 0.12671143, Loss/total_loss = 0.16914669, global_step = 4896, learning_rate = 1e-04, loss = 0.16914669\n",
            "I0624 00:56:36.097882 139948988630912 estimator.py:2049] Saving dict for global step 4896: DetectionBoxes_Precision/mAP = 0.697726, DetectionBoxes_Precision/mAP (large) = 0.67134786, DetectionBoxes_Precision/mAP (medium) = 0.74019545, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9732262, DetectionBoxes_Precision/mAP@.75IOU = 0.881411, DetectionBoxes_Recall/AR@1 = 0.73661417, DetectionBoxes_Recall/AR@10 = 0.7559055, DetectionBoxes_Recall/AR@100 = 0.75905514, DetectionBoxes_Recall/AR@100 (large) = 0.72686565, DetectionBoxes_Recall/AR@100 (medium) = 0.795, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.028203804, Loss/BoxClassifierLoss/localization_loss = 0.010833929, Loss/RPNLoss/localization_loss = 0.0033976466, Loss/RPNLoss/objectness_loss = 0.12671143, Loss/total_loss = 0.16914669, global_step = 4896, learning_rate = 1e-04, loss = 0.16914669\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4896: training/model.ckpt-4896\n",
            "I0624 00:56:36.105993 139948988630912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 4896: training/model.ckpt-4896\n",
            "INFO:tensorflow:global_step/sec: 0.527931\n",
            "I0624 00:56:40.195976 139948988630912 basic_session_run_hooks.py:692] global_step/sec: 0.527931\n",
            "INFO:tensorflow:loss = 0.06327583, step = 4900 (189.419 sec)\n",
            "I0624 00:56:40.197005 139948988630912 basic_session_run_hooks.py:260] loss = 0.06327583, step = 4900 (189.419 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into training/model.ckpt.\n",
            "I0624 00:58:00.673394 139948988630912 basic_session_run_hooks.py:606] Saving checkpoints for 5000 into training/model.ckpt.\n",
            "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "I0624 00:58:03.128345 139948988630912 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0624 00:58:03.145380 139948988630912 dataset_builder.py:162] Reading unweighted datasets: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "I0624 00:58:03.147905 139948988630912 dataset_builder.py:79] Reading record datasets for input file: ['/content/drive/MyDrive/B004_context_rcnn_memory_test']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0624 00:58:03.148029 139948988630912 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0624 00:58:03.148103 139948988630912 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0624 00:58:03.869864 139948988630912 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:58:03.898482 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:58:06.505530 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:58:06.623912 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0624 00:58:06.624297 139948988630912 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:58:07.066435 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:58:07.312783 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:58:07.327981 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:58:07.703248 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0624 00:58:09.384996 139948988630912 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2022-06-24T00:58:09Z\n",
            "I0624 00:58:09.399616 139948988630912 evaluation.py:255] Starting evaluation at 2022-06-24T00:58:09Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0624 00:58:10.026756 139948988630912 monitored_session.py:240] Graph was finalized.\n",
            "2022-06-24 00:58:10.027350: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:58:10.027743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-06-24 00:58:10.027843: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-24 00:58:10.027871: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-24 00:58:10.027900: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-06-24 00:58:10.027924: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-06-24 00:58:10.027953: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-06-24 00:58:10.027979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-06-24 00:58:10.028005: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-06-24 00:58:10.028094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:58:10.028446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:58:10.028718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-06-24 00:58:10.028758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-06-24 00:58:10.028772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-06-24 00:58:10.028782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-06-24 00:58:10.028876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:58:10.029217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:58:10.029510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-5000\n",
            "I0624 00:58:10.030517 139948988630912 saver.py:1284] Restoring parameters from training/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0624 00:58:11.647095 139948988630912 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0624 00:58:11.850590 139948988630912 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 564 images.\n",
            "I0624 00:59:45.605354 139946434746112 coco_evaluation.py:293] Performing evaluation on 564 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0624 00:59:45.607303 139946434746112 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.08s)\n",
            "I0624 00:59:45.702999 139946434746112 coco_tools.py:138] DONE (t=0.08s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=2.34s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.34s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.706\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.973\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.889\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.750\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.678\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.746\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.761\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.765\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.803\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.730\n",
            "INFO:tensorflow:Finished evaluation at 2022-06-24-00:59:48\n",
            "I0624 00:59:48.599896 139948988630912 evaluation.py:275] Finished evaluation at 2022-06-24-00:59:48\n",
            "INFO:tensorflow:Saving dict for global step 5000: DetectionBoxes_Precision/mAP = 0.705966, DetectionBoxes_Precision/mAP (large) = 0.6776887, DetectionBoxes_Precision/mAP (medium) = 0.7500637, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9731775, DetectionBoxes_Precision/mAP@.75IOU = 0.8886456, DetectionBoxes_Recall/AR@1 = 0.7456693, DetectionBoxes_Recall/AR@10 = 0.7614173, DetectionBoxes_Recall/AR@100 = 0.76456696, DetectionBoxes_Recall/AR@100 (large) = 0.72985077, DetectionBoxes_Recall/AR@100 (medium) = 0.80333334, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.027272081, Loss/BoxClassifierLoss/localization_loss = 0.010600292, Loss/RPNLoss/localization_loss = 0.0033905369, Loss/RPNLoss/objectness_loss = 0.1277678, Loss/total_loss = 0.16903055, global_step = 5000, learning_rate = 1e-04, loss = 0.16903055\n",
            "I0624 00:59:48.600177 139948988630912 estimator.py:2049] Saving dict for global step 5000: DetectionBoxes_Precision/mAP = 0.705966, DetectionBoxes_Precision/mAP (large) = 0.6776887, DetectionBoxes_Precision/mAP (medium) = 0.7500637, DetectionBoxes_Precision/mAP (small) = -1.0, DetectionBoxes_Precision/mAP@.50IOU = 0.9731775, DetectionBoxes_Precision/mAP@.75IOU = 0.8886456, DetectionBoxes_Recall/AR@1 = 0.7456693, DetectionBoxes_Recall/AR@10 = 0.7614173, DetectionBoxes_Recall/AR@100 = 0.76456696, DetectionBoxes_Recall/AR@100 (large) = 0.72985077, DetectionBoxes_Recall/AR@100 (medium) = 0.80333334, DetectionBoxes_Recall/AR@100 (small) = -1.0, Loss/BoxClassifierLoss/classification_loss = 0.027272081, Loss/BoxClassifierLoss/localization_loss = 0.010600292, Loss/RPNLoss/localization_loss = 0.0033905369, Loss/RPNLoss/objectness_loss = 0.1277678, Loss/total_loss = 0.16903055, global_step = 5000, learning_rate = 1e-04, loss = 0.16903055\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: training/model.ckpt-5000\n",
            "I0624 00:59:48.608358 139948988630912 estimator.py:2109] Saving 'checkpoint_path' summary for global step 5000: training/model.ckpt-5000\n",
            "INFO:tensorflow:Performing the final export in the end of training.\n",
            "I0624 00:59:48.609172 139948988630912 exporter.py:410] Performing the final export in the end of training.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0624 00:59:48.879840 139948988630912 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:59:48.890805 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:59:51.878613 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:59:51.994787 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0624 00:59:51.995154 139948988630912 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:59:52.426556 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:59:52.697669 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:59:52.712671 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 00:59:53.129407 139948988630912 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0624 00:59:53.628926 139948988630912 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0624 00:59:53.629184 139948988630912 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "I0624 00:59:53.629815 139948988630912 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "I0624 00:59:53.629949 139948988630912 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "I0624 00:59:53.630027 139948988630912 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
            "I0624 00:59:53.630100 139948988630912 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
            "I0624 00:59:53.630174 139948988630912 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
            "2022-06-24 00:59:53.630650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:59:53.631015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-06-24 00:59:53.631105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-24 00:59:53.631133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-24 00:59:53.631157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-06-24 00:59:53.631181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-06-24 00:59:53.631203: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-06-24 00:59:53.631225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-06-24 00:59:53.631249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-06-24 00:59:53.631338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:59:53.631721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:59:53.632010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-06-24 00:59:53.632052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-06-24 00:59:53.632066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-06-24 00:59:53.632076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-06-24 00:59:53.632176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:59:53.632513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 00:59:53.632794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-5000\n",
            "I0624 00:59:53.634930 139948988630912 saver.py:1284] Restoring parameters from training/model.ckpt-5000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "I0624 00:59:54.496414 139948988630912 builder_impl.py:665] Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0624 00:59:54.496652 139948988630912 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: training/export/Servo/temp-b'1656032388'/saved_model.pb\n",
            "I0624 00:59:56.078165 139948988630912 builder_impl.py:425] SavedModel written to: training/export/Servo/temp-b'1656032388'/saved_model.pb\n",
            "INFO:tensorflow:Loss for final step: 0.040258307.\n",
            "I0624 00:59:56.418252 139948988630912 estimator.py:371] Loss for final step: 0.040258307.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3adc693-0d97-49c1-a703-700a9f4fcec8"
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint\n",
            "eval_0\n",
            "events.out.tfevents.1656027266.6ba329dd8c4c\n",
            "export\n",
            "graph.pbtxt\n",
            "model.ckpt-3108.data-00000-of-00001\n",
            "model.ckpt-3108.index\n",
            "model.ckpt-3108.meta\n",
            "model.ckpt-3699.data-00000-of-00001\n",
            "model.ckpt-3699.index\n",
            "model.ckpt-3699.meta\n",
            "model.ckpt-4292.data-00000-of-00001\n",
            "model.ckpt-4292.index\n",
            "model.ckpt-4292.meta\n",
            "model.ckpt-4896.data-00000-of-00001\n",
            "model.ckpt-4896.index\n",
            "model.ckpt-4896.meta\n",
            "model.ckpt-5000.data-00000-of-00001\n",
            "model.ckpt-5000.index\n",
            "model.ckpt-5000.meta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "z4psLp5RQmg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa"
      },
      "source": [
        "## Exporting a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85042c32-eabd-40a6-c73b-54d4b604c7bc"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path {pipeline_fname} \\\n",
        "    --output_directory \"/content/Faster_RCNN_SS_imagetensor\" \\\n",
        "    --trained_checkpoint_prefix {last_model_path} \\\n",
        "    --additional_output_tensor_names detection_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training/model.ckpt-5000\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 01:04:25.689388 139934068746112 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0624 01:04:25.691389 139934068746112 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 01:04:28.274828 139934068746112 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 01:04:28.389126 139934068746112 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0624 01:04:28.389498 139934068746112 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/box_list_ops.py:169: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0624 01:04:28.442623 139934068746112 deprecation.py:323] From /content/models/research/object_detection/core/box_list_ops.py:169: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:479: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0624 01:04:29.052391 139934068746112 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:479: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 01:04:29.067613 139934068746112 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0624 01:04:29.310840 139934068746112 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 01:04:29.315389 139934068746112 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 01:04:29.332069 139934068746112 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0624 01:04:29.924357 139934068746112 regularizers.py:99] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:481: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0624 01:04:30.030263 139934068746112 deprecation.py:323] From /content/models/research/object_detection/exporter.py:481: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:660: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0624 01:04:30.033319 139934068746112 deprecation.py:323] From /content/models/research/object_detection/exporter.py:660: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0624 01:04:30.034327 139934068746112 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "251 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/62.11m params)\n",
            "  Conv (--/4.72m params)\n",
            "    Conv/biases (512, 512/512 params)\n",
            "    Conv/weights (3x3x1024x512, 4.72m/4.72m params)\n",
            "  FirstStageBoxPredictor (--/36.94k params)\n",
            "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
            "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "  FirstStageFeatureExtractor (--/42.39m params)\n",
            "    FirstStageFeatureExtractor/resnet_v1_101 (--/42.39m params)\n",
            "      FirstStageFeatureExtractor/resnet_v1_101/block1 (--/212.99k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1 (--/4.10k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/weights (1x1x64x64, 4.10k/4.10k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2 (--/36.86k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3 (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2 (--/69.63k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1 (--/69.63k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1 (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2 (--/36.86k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3 (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3 (--/69.63k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1 (--/69.63k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1 (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2 (--/36.86k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3 (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "      FirstStageFeatureExtractor/resnet_v1_101/block2 (--/1.21m params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1 (--/376.83k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1 (--/376.83k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1 (--/32.77k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut (--/131.07k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/weights (1x1x256x512, 131.07k/131.07k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2 (--/278.53k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1 (--/278.53k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3 (--/278.53k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1 (--/278.53k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4 (--/278.53k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1 (--/278.53k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "      FirstStageFeatureExtractor/resnet_v1_101/block3 (--/26.02m params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1 (--/1.51m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1 (--/1.51m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1 (--/131.07k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/weights (1x1x512x256, 131.07k/131.07k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut (--/524.29k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/weights (1x1x512x1024, 524.29k/524.29k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "      FirstStageFeatureExtractor/resnet_v1_101/block4 (--/14.94m params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1 (--/6.03m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1 (--/6.03m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1 (--/524.29k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights (1x1x1024x512, 524.29k/524.29k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut (--/2.10m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights (1x1x1024x2048, 2.10m/2.10m params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2 (--/4.46m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1 (--/4.46m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1 (--/1.05m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3 (--/4.46m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1 (--/4.46m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1 (--/1.05m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "      FirstStageFeatureExtractor/resnet_v1_101/conv1 (--/9.41k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/conv1/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/conv1/weights (7x7x3x64, 9.41k/9.41k params)\n",
            "  SecondStageBoxPredictor (--/12.29k params)\n",
            "    SecondStageBoxPredictor/BoxEncodingPredictor (--/8.20k params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/biases (4, 4/4 params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/weights (2048x4, 8.19k/8.19k params)\n",
            "    SecondStageBoxPredictor/ClassPredictor (--/4.10k params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/biases (2, 2/2 params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/weights (2048x2, 4.10k/4.10k params)\n",
            "  SecondStageFeatureExtractor (--/14.94m params)\n",
            "    SecondStageFeatureExtractor/resnet_v1_101 (--/14.94m params)\n",
            "      SecondStageFeatureExtractor/resnet_v1_101/block4 (--/14.94m params)\n",
            "        SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1 (--/6.03m params)\n",
            "          SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1 (--/6.03m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1 (--/524.29k params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights (1x1x1024x512, 524.29k/524.29k params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut (--/2.10m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights (1x1x1024x2048, 2.10m/2.10m params)\n",
            "        SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2 (--/4.46m params)\n",
            "          SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1 (--/4.46m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1 (--/1.05m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "        SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3 (--/4.46m params)\n",
            "          SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1 (--/4.46m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1 (--/1.05m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "\n",
            "======================End of Report==========================\n",
            "251 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/6.17k flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  map_2/while/mul_3 (300/300 flops)\n",
            "  map_2/while/mul_2 (300/300 flops)\n",
            "  map_2/while/mul_1 (300/300 flops)\n",
            "  map_2/while/mul (300/300 flops)\n",
            "  GridAnchorGenerator/truediv (12/12 flops)\n",
            "  GridAnchorGenerator/mul (12/12 flops)\n",
            "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
            "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
            "  FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/required_space_to_batch_paddings/sub (2/2 flops)\n",
            "  FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/required_space_to_batch_paddings/sub (2/2 flops)\n",
            "  FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/required_space_to_batch_paddings/sub (2/2 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  mul (1/1 flops)\n",
            "  map_2/while/Less_1 (1/1 flops)\n",
            "  map_2/while/Less (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map_1/while/Less_1 (1/1 flops)\n",
            "  map_1/while/Less (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map/while/Less_1 (1/1 flops)\n",
            "  map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv_1 (1/1 flops)\n",
            "  SecondStageDetectionFeaturesExtract/mul (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "2022-06-24 01:04:32.586269: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-06-24 01:04:32.614505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:32.615112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-06-24 01:04:32.615395: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-24 01:04:32.616474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-24 01:04:32.617544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-06-24 01:04:32.617889: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-06-24 01:04:32.619239: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-06-24 01:04:32.620247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-06-24 01:04:32.624236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-06-24 01:04:32.624356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:32.625010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:32.625647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-06-24 01:04:32.625975: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-06-24 01:04:32.630721: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-06-24 01:04:32.630896: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2afb640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-06-24 01:04:32.630932: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-06-24 01:04:32.840907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:32.841677: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xea0ce00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-06-24 01:04:32.841710: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2022-06-24 01:04:32.841894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:32.842535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-06-24 01:04:32.842646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-24 01:04:32.842684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-24 01:04:32.842709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-06-24 01:04:32.842730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-06-24 01:04:32.842751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-06-24 01:04:32.842771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-06-24 01:04:32.842793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-06-24 01:04:32.842876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:32.843501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:32.844037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-06-24 01:04:32.844165: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-24 01:04:32.845458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-06-24 01:04:32.845488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-06-24 01:04:32.845504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-06-24 01:04:32.845631: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:32.846208: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:32.846773: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-06-24 01:04:32.846818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-5000\n",
            "I0624 01:04:32.848466 139934068746112 saver.py:1284] Restoring parameters from training/model.ckpt-5000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0624 01:04:35.693065 139934068746112 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2022-06-24 01:04:36.536166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:36.536760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-06-24 01:04:36.536845: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-24 01:04:36.536871: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-24 01:04:36.536894: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-06-24 01:04:36.536920: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-06-24 01:04:36.536940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-06-24 01:04:36.536960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-06-24 01:04:36.536981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-06-24 01:04:36.537070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:36.537624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:36.538102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-06-24 01:04:36.538141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-06-24 01:04:36.538155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-06-24 01:04:36.538165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-06-24 01:04:36.538259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:36.538793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:36.539286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-5000\n",
            "I0624 01:04:36.540568 139934068746112 saver.py:1284] Restoring parameters from training/model.ckpt-5000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0624 01:04:37.627436 139934068746112 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0624 01:04:37.627693 139934068746112 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 530 variables.\n",
            "I0624 01:04:38.171821 139934068746112 graph_util_impl.py:334] Froze 530 variables.\n",
            "INFO:tensorflow:Converted 530 variables to const ops.\n",
            "I0624 01:04:38.443608 139934068746112 graph_util_impl.py:394] Converted 530 variables to const ops.\n",
            "2022-06-24 01:04:39.083503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:39.084308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-06-24 01:04:39.085304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2022-06-24 01:04:39.085406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2022-06-24 01:04:39.085467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2022-06-24 01:04:39.085495: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2022-06-24 01:04:39.085521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2022-06-24 01:04:39.085544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2022-06-24 01:04:39.085565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-06-24 01:04:39.085682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:39.086498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:39.087187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2022-06-24 01:04:39.087237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-06-24 01:04:39.087255: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-06-24 01:04:39.087268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2022-06-24 01:04:39.088613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:39.090494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-06-24 01:04:39.091225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14257 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:391: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0624 01:04:39.929023 139934068746112 deprecation.py:323] From /content/models/research/object_detection/exporter.py:391: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0624 01:04:39.929758 139934068746112 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0624 01:04:39.929894 139934068746112 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/Faster_RCNN_SS_imagetensor/saved_model/saved_model.pb\n",
            "I0624 01:04:40.783507 139934068746112 builder_impl.py:425] SavedModel written to: /content/Faster_RCNN_SS_imagetensor/saved_model/saved_model.pb\n",
            "INFO:tensorflow:Writing pipeline config file to /content/Faster_RCNN_SS_imagetensor/pipeline.config\n",
            "I0624 01:04:40.908696 139934068746112 config_util.py:254] Writing pipeline config file to /content/Faster_RCNN_SS_imagetensor/pipeline.config\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usgBZvkz0nqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd2c0d37-cc15-41cc-c1fb-7a51d3343dc9"
      },
      "source": [
        "!ls {output_directory}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access './fine_tuned_model': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r \"/content/Faster_RCNN_SS_imagetensor.zip\" \"/content/Faster_RCNN_SS_imagetensor\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QVSVKlAKHca",
        "outputId": "1cf4215b-a59a-477e-d684-e39735b7b2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/Faster_RCNN_SS_imagetensor/ (stored 0%)\n",
            "  adding: content/Faster_RCNN_SS_imagetensor/model.ckpt.meta (deflated 94%)\n",
            "  adding: content/Faster_RCNN_SS_imagetensor/pipeline.config (deflated 67%)\n",
            "  adding: content/Faster_RCNN_SS_imagetensor/model.ckpt.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/Faster_RCNN_SS_imagetensor/frozen_inference_graph.pb (deflated 8%)\n",
            "  adding: content/Faster_RCNN_SS_imagetensor/saved_model/ (stored 0%)\n",
            "  adding: content/Faster_RCNN_SS_imagetensor/saved_model/saved_model.pb (deflated 8%)\n",
            "  adding: content/Faster_RCNN_SS_imagetensor/saved_model/variables/ (stored 0%)\n",
            "  adding: content/Faster_RCNN_SS_imagetensor/model.ckpt.index (deflated 77%)\n",
            "  adding: content/Faster_RCNN_SS_imagetensor/checkpoint (deflated 42%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/Faster_RCNN_SS_imagetensor.zip\" \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "0NwawksKNcgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p09AOThWkaQv"
      },
      "source": [
        "## Download the model `.pb` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnDo1lonKgFr"
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHqWkLBINYoI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f5fb626-b659-43bd-a39a-1f487c0d609c"
      },
      "source": [
        "!ls -alh {pb_fname}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 182M Jun 22 20:42 /content/models/research/fine_tuned_model/frozen_inference_graph.pb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIqnjbWYsuQw"
      },
      "source": [
        "### Option1 : upload the `.pb` file to your Google Drive\n",
        "Then download it from your Google Drive to local file system.\n",
        "\n",
        "During this step, you will be prompted to enter the token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAqyASIJqjae"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fname = os.path.basename(pb_fname)\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': fname})\n",
        "uploaded.SetContentFile(pb_fname)\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FKFq8RXs6bs"
      },
      "source": [
        "### Option2 :  Download the `.pb` file directly to your local file system\n",
        "This method may not be stable when downloading large files like the model `.pb` file. Try **option 1** instead if not working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bP0iMMnnr77"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(pb_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFyCeiBb9BbS"
      },
      "source": [
        "### OPTIONAL: Download the `label_map.pbtxt` file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1TbL6Ox8q6Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8e002aab-4bb2-419f-d1cf-5d10c1b0cad1"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(label_map_pbtxt_fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_af9afc60-b167-4049-9000-1211c1bffaa5\", \"tortoise_label_map.pbtxt\", 71)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUmAo9foa1xq"
      },
      "source": [
        "### OPTIONAL: Download the modified pipline file\n",
        "If you plan to use OpenVINO toolkit to convert the `.pb` file to inference faster on Intel's hardware (CPU/GPU, Movidius, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pql2QpemazE1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ae2d3e08-30ed-4d66-a15c-66199db49501"
      },
      "source": [
        "files.download(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_235729b8-7d02-48be-824b-968d41e89bfd\", \"pipeline.config\", 3454)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1AgBj1l0v_W"
      },
      "source": [
        "!tar cfz fine_tuned_model.tar.gz fine_tuned_model\n",
        "from google.colab import files\n",
        "files.download('fine_tuned_model.tar.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnx57Mbe72yY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz1gX19GlVW7"
      },
      "source": [
        "## Run inference test\n",
        "\n",
        "To test on your own images, you need to upload raw test images to the `test` folder located inside `/data`.\n",
        "\n",
        "Right now, this folder contains TFRecord files from Roboflow. We need the raw images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nE33fiM9WD5"
      },
      "source": [
        "#### Add test images to this notebook\n",
        "\n",
        "We can download the exact same raw images that are in our Roboflow test split to our local computer by downloading the images in a different (non-TFRecord) format.\n",
        "\n",
        "Go back to our [dataset](https://public.roboflow.ai/object-detection/bccd/1), click \"Download,\" select \"COCO JSON\" as the format, and download to your local machine.\n",
        "\n",
        "Unzip the downloaded file, and navigate to the `test` directory.\n",
        "![folder](https://i.imgur.com/xkjxmKP.png)\n",
        "\n",
        "\n",
        "Now, on the left-hand side in the colab notebook, select the folder icon.\n",
        "![Colab folder](https://i.imgur.com/59v08qG.png)\n",
        "\n",
        "Right-click on `test`, and select \"Upload.\" Navigate to the files locally on your machine you just downloaded...and voila! You're set!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45ENiVg_74Lf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3fbac66d-344d-4127-9ff5-5114d4bea248"
      },
      "source": [
        "# optionally, remove the TFRecord and cells_label_map.pbtxt from\n",
        "# the test directory so it is only raw images\n",
        "%cd {repo_dir_path}\n",
        "%cd data/test\n",
        "%rm cells.tfrecord\n",
        "%rm cells_label_map.pbtxt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "/content/tensorflow-object-detection-faster-rcnn/data/test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzj9A4e5mj5l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1cf77694-1486-4a54-ad8b-89e1bf9b33f8"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = pb_fname\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = label_map_pbtxt_fname\n",
        "\n",
        "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
        "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"data/test\")\n",
        "\n",
        "assert os.path.isfile(pb_fname)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "if len(TEST_IMAGE_PATHS) == 0:\n",
        "  sample_img = 'https://storage.googleapis.com/roboflow-platform-transforms/Ly2DeBzbwsemGd2ReHk4BFxy8683/cf5ed147e4f2675fbabbc9b0db750ecf/transformed.jpg'\n",
        "  import urllib.request\n",
        "  urllib.request.urlretrieve(sample_img, \n",
        "                            PATH_TO_TEST_IMAGES_DIR + \"/cell.jpg\")\n",
        "\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00284_jpg.rf.d33fcb37af7c55a50f275711763ddf7a.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00302_jpg.rf.ae0f61c17483b2e0e7f9b1396fc5108c.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00062_jpg.rf.e965ee152eea462d82706a2709abfe00.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00359_jpg.rf.e4b6af6691f2d8cc8345f42bcc1678fa.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00227_jpg.rf.1572183909350ffe748751e967b7c8e5.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00336_jpg.rf.5ae87ede3994ca14504136035e256e38.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00112_jpg.rf.f8d86689750221da637a054843c72822.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00154_jpg.rf.7c682b32a64ca0520b6fc725f0d667c7.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00044_jpg.rf.b0e2369642c5a7fa434ed8defa79e2ba.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00133_jpg.rf.06c3705fcfe2fcaee19e1a076e511508.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00325_jpg.rf.55e62842be833601c86a1bd449ee8fe6.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00266_jpg.rf.6d62684a33e2f5bc048803aba3177f58.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00254_jpg.rf.6e046ca48ec2e57c2e178aa3f08ec8ee.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00241_jpg.rf.d0edd8c528bec298a9552ed8ad5714c7.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00334_jpg.rf.3b8a84d57940aeb45e5c2046c8411996.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00235_jpg.rf.b01cbde1f504d448759188feadad4838.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00090_jpg.rf.4fd1da847d2857b6092003c41255ea4c.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00038_jpg.rf.63da20f3f5538d0d2be8c4633c7034a1.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00337_jpg.rf.7959cb18929c970939cda4a9544547c8.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00278_jpg.rf.9ce9e9760ff20b56b115c86879e02a67.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00160_jpg.rf.500f16e32681898ca1ce052ea0402c08.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00301_jpg.rf.9c427e66bcc1b088df9a5e71c0abefba.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00385_jpg.rf.cf0e48c08597f372423a60918074f574.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00113_jpg.rf.a6d6a75c0ebfc703ecff95e2938be34d.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00289_jpg.rf.58c541d9273174738d3d74e599428169.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00120_jpg.rf.6742a4da047e1226a181d2de2978ce6d.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00386_jpg.rf.1de8e2e0e94f942d7a1523852d7fb146.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00204_jpg.rf.6c3c9e37ab9122b026444cc4e685aef1.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00099_jpg.rf.5b178d758af2a97d3df8e5f87b1f344a.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00275_jpg.rf.9108b9a016fadd9c367b05dfb0c40c2c.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00369_jpg.rf.99ae139e5530a25980b7acdd56a4317c.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00134_jpg.rf.ee0308b1f3e1ffbb048cb3b1f80e8e36.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00265_jpg.rf.4b7cc25caca963b5e0325c6998917cd1.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00190_jpg.rf.03484116dcad7715c77d30654056fc54.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00191_jpg.rf.d4b5ad6525c6c0bc4eaea1f24901f396.jpg', '/content/tensorflow-object-detection-faster-rcnn/data/test/BloodImage_00350_jpg.rf.1a19e9f9f197fbeab278718f7c6cea9b.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNFc5CM3Duav",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37a1477d-7382-4e77-9b4f-eb69bc104b02"
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG5YUMdg1Po7"
      },
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IbKIjbY_MRk"
      },
      "source": [
        "# Output images not showing? Run this cell again, and try the cell above\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah9YKYOX9qrH"
      },
      "source": [
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}